services:
  # =============================================================================
  # APPLICATION SERVICES
  # =============================================================================

  frontend:
    build:
      context: ${REPOS_DIR:-./repos}/pizzamaker-fe
      dockerfile: deployments/Dockerfile
      cache_from:
        - frontend:latest
    image: frontend:latest
    ports:
      - "${PIZZAMAKER_FE_PORT:-3000}:80"
    environment:
      REACT_APP_API_BASE_URL: ${KONG_API_BASE_URL:-http://localhost:8000/api/v1}
    depends_on:
      - kong-gateway
    restart: on-failure
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:80"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  recipe-manager:
    build:
      context: ${REPOS_DIR:-./repos}/recipe-manager
      dockerfile: deployments/Dockerfile
      cache_from:
        - recipe-manager:latest
    image: recipe-manager:latest
    # Port removed - only accessible through Kong Gateway
    expose:
      - "8080"  # Internal port for Kong upstream
    environment:
      CALCULATOR_ADDR: calculator:50051
      INGREDIENTS_BALANCER_ADDR: ingredients-balancer:50052
      CONFIG_PATH: /app/configs
      DATABASE_HOST: mysql
      DATABASE_PORT: 3306
      DATABASE_DBNAME: pizzamaker
      DATABASE_USER: user
      DATABASE_PASSWORD: pizzamaker
      LOG_LEVEL: ${LOG_LEVEL:-info}
      OTEL_SERVICE_NAME: recipe-manager
      OTEL_EXPORTER_OTLP_ENDPOINT: jaeger:4318
      # Kong integration
      KONG_ADMIN_URL: http://kong-gateway:8001
      ENABLE_KONG_TRACING: "true"
    depends_on:
      mysql:
        condition: service_healthy
      jaeger:
        condition: service_started
      fluentd:
        condition: service_started
    restart: on-failure
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async: "true"
        tag: recipe-manager
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  ingredients-balancer:
    build:
      context: ${REPOS_DIR:-./repos}/ingredients-balancer
      dockerfile: deployments/Dockerfile
      cache_from:
        - ingredients-balancer:latest
    image: ingredients-balancer:latest
    expose:
      - "50052"  # gRPC internal
      - "8081"   # HTTP metrics for Prometheus
    environment:
      LOG_LEVEL: ${LOG_LEVEL:-info}
      OTEL_SERVICE_NAME: ingredients-balancer
      OTEL_EXPORTER_OTLP_ENDPOINT: jaeger:4318
      KONG_ADMIN_URL: http://kong-gateway:8001
    depends_on:
      jaeger:
        condition: service_started
    restart: on-failure
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 50052 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  calculator:
    build:
      context: ${REPOS_DIR:-./repos}/calculator
      dockerfile: deployments/Dockerfile
      cache_from:
        - calculator:latest
    image: calculator:latest
    expose:
      - "50051"  # gRPC internal
      - "8080"   # HTTP metrics for Prometheus
    environment:
      LOG_LEVEL: ${LOG_LEVEL:-info}
      OTEL_SERVICE_NAME: calculator
      OTEL_EXPORTER_OTLP_ENDPOINT: jaeger:4318
      KONG_ADMIN_URL: http://kong-gateway:8001
    depends_on:
      jaeger:
        condition: service_started
    restart: on-failure
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 50051 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  mysql:
    image: mysql:8.0
    container_name: mysql_db
    restart: on-failure
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: pizzamaker
      MYSQL_USER: user
      MYSQL_PASSWORD: pizzamaker
    ports:
      - "${MYSQL_PORT:-3306}:3306"
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "user", "--password=pizzamaker"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s
    volumes:
      - mysql_data:/var/lib/mysql
      - ${REPOS_DIR:-./repos}/recipe-manager/migrations:/docker-entrypoint-initdb.d
    command: ['mysqld', '--character-set-server=utf8mb4', '--collation-server=utf8mb4_unicode_ci']

  jaeger:
    image: jaegertracing/all-in-one:1.60
    container_name: jaeger
    restart: on-failure
    environment:
      COLLECTOR_OTLP_ENABLED: true
      COLLECTOR_OTLP_HTTP_PORT: 4318
      COLLECTOR_OTLP_GRPC_PORT: 4317
    ports:
      - "${JAEGER_UI_PORT:-16686}:16686"
      - "${JAEGER_COLLECTOR_PORT:-14268}:14268"
      - "${JAEGER_OTLP_GRPC_PORT:-4317}:4317"
      - "${JAEGER_OTLP_HTTP_PORT:-4318}:4318"
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:16686"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  prometheus:
    image: prom/prometheus:v2.49.1
    container_name: prometheus
    restart: on-failure
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    depends_on:
      recipe-manager:
        condition: service_healthy
      calculator:
        condition: service_started
      ingredients-balancer:
        condition: service_started
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s

  grafana:
    image: grafana/grafana:10.2.3
    container_name: grafana
    restart: on-failure
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: false
      GF_SERVER_DOMAIN: localhost
      GF_LOG_LEVEL: info
      GF_LOG_MODE: console
    ports:
      - "${GRAFANA_PORT:-3001}:3000"
    volumes:
      - ./infrastructure/monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./infrastructure/monitoring/grafana/dashboards:/var/lib/grafana/dashboards
      - grafana_data:/var/lib/grafana
    depends_on:
      prometheus:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s

  elasticsearch-logs:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.15
    container_name: elasticsearch-logs
    restart: on-failure
    environment:
      - node.name=elasticsearch-logs
      - cluster.name=pizzamaker-logs
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    ports:
      - "${ELASTICSEARCH_PORT:-9200}:9200"
    volumes:
      - ./infrastructure/monitoring/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
      - elasticsearch_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  fluentd:
    build:
      context: ./infrastructure/monitoring/fluentd
      dockerfile: Dockerfile
    container_name: fluentd
    restart: on-failure
    ports:
      - "${FLUENTD_PORT:-24224}:24224"
      - "${FLUENTD_PORT:-24224}:24224/udp"
    volumes:
      - ./infrastructure/monitoring/fluentd/fluent.conf:/fluentd/etc/fluent.conf:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - fluentd_data:/var/log/fluentd-buffers
    depends_on:
      elasticsearch-logs:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "24224"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  kibana-logs:
    image: docker.elastic.co/kibana/kibana:7.17.15
    container_name: kibana-logs
    restart: on-failure
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch-logs:9200
      ELASTICSEARCH_USERNAME: ""
      ELASTICSEARCH_PASSWORD: ""
    ports:
      - "${KIBANA_PORT:-5601}:5601"
    volumes:
      - ./infrastructure/monitoring/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
      - kibana_data:/usr/share/kibana/data
    depends_on:
      elasticsearch-logs:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5601/api/status"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # =============================================================================
  # KONG API GATEWAY INFRASTRUCTURE
  # =============================================================================

  kong-database:
    image: postgres:15-alpine
    container_name: kong-database
    restart: on-failure
    environment:
      POSTGRES_USER: kong
      POSTGRES_DB: kong
      POSTGRES_PASSWORD: kongpass
      POSTGRES_HOST_AUTH_METHOD: trust
    volumes:
      - kong_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "kong"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 30s
    networks:
      - kong-net

  kong-migrations:
    image: kong:3.5.0
    container_name: kong-migrations
    command: kong migrations bootstrap
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: kong-database
      KONG_PG_PORT: 5432
      KONG_PG_USER: kong
      KONG_PG_PASSWORD: kongpass
      KONG_PG_DATABASE: kong
    depends_on:
      kong-database:
        condition: service_healthy
    restart: on-failure
    networks:
      - kong-net

  kong-gateway:
    image: kong:3.5.0
    container_name: kong-gateway
    restart: on-failure
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: kong-database
      KONG_PG_PORT: 5432
      KONG_PG_USER: kong
      KONG_PG_PASSWORD: kongpass
      KONG_PG_DATABASE: kong
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_ADMIN_LISTEN: "0.0.0.0:8001"
      KONG_ADMIN_GUI_LISTEN: "0.0.0.0:8002"
      KONG_PROXY_LISTEN: "0.0.0.0:8000, 0.0.0.0:8443 ssl"
      KONG_PLUGINS: "bundled"
      KONG_LOG_LEVEL: info
    ports:
      - "${KONG_PROXY_PORT:-8000}:8000"      # Kong Proxy HTTP
      - "${KONG_PROXY_SSL_PORT:-8443}:8443"  # Kong Proxy HTTPS
      - "${KONG_ADMIN_PORT:-8001}:8001"      # Kong Admin API
      - "${KONG_ADMIN_GUI_PORT:-8002}:8002"  # Kong Admin GUI
    depends_on:
      kong-migrations:
        condition: service_completed_successfully
      recipe-manager:
        condition: service_healthy
      calculator:
        condition: service_started
      ingredients-balancer:
        condition: service_started
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 30s
    volumes:
      - ./infrastructure/gateway/kong:/usr/local/kong/declarative
    networks:
      - kong-net
      - default
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async: "true"
        tag: kong-gateway

volumes:
  mysql_data:
  prometheus_data:
  grafana_data:
  elasticsearch_data:
  fluentd_data:
  kibana_data:
  kong_data:

networks:
  kong-net:
    driver: bridge
